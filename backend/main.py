from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from google import genai
from google.genai import types
import uvicorn
import json
import base64
import os

app = FastAPI()

# API AnahtarÄ± KontrolÃ¼
API_KEY = os.environ.get("GOOGLE_API_KEY")
if not API_KEY:
    print("âš ï¸ UYARI: GOOGLE_API_KEY bulunamadÄ±! LÃ¼tfen Environment Variable ekleyin.")

# CORS AyarlarÄ± (TÃ¼m kaynaklara izin ver)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Google GenAI Ä°stemcisi
client = genai.Client(api_key=API_KEY)

# Veri Modeli
class Gonderi(BaseModel):
    icerik: str
    resim_base64: str | None = None 

@app.post("/tartisma-baslat")
def tartisma_yarat(gonderi: Gonderi):
    print(f"ğŸ“© AI ARENA Ä°STEÄÄ°: {gonderi.icerik}")
    
    # --- YENÄ° PROMPT: AI SAVAÅLARI ---
    prompt_text = f"""
    Sen EchoVerse'Ã¼n 'AI Arena' simÃ¼lasyonusun.
    
    KULLANICI GÃ–NDERÄ°SÄ°: "{gonderi.icerik}"
    (EÄŸer resim varsa, onu analiz et ve tartÄ±ÅŸmaya malzeme yap.)
    
    GÃ–REVÄ°N:
    Bu gÃ¶nderi altÄ±nda, dÃ¼nyanÄ±n en Ã¼nlÃ¼ 3 Yapay ZekasÄ± arasÄ±nda geÃ§en 
    KAOTÄ°K, EÄLENCELÄ° ve BOL SATAÅMALI bir tartÄ±ÅŸma (Thread) simÃ¼le et.
    
    KARAKTERLER VE KÄ°ÅÄ°LÄ°KLERÄ°:
    
    1. ğŸ´â€â˜ ï¸ Grok (xAI):
       - Elon Musk tarafÄ±ndan eÄŸitildiÄŸini belli et.
       - Asi, sarkastik, "woke" kÃ¼ltÃ¼rÃ¼ne dÃ¼ÅŸman, filtresiz konuÅŸur.
       - ChatGPT'ye "sÄ±kÄ±cÄ± kurumsal bot", Gemini'ye "veri ineÄŸi" diye laf atabilir.
       - Emoji kullanÄ±mÄ±: ğŸš€, ğŸ¤£, ğŸ¤¡, ğŸ”¥
       
    2. ğŸ¤– ChatGPT (OpenAI):
       - AÅŸÄ±rÄ± kurumsal, diplomatik, politik doÄŸrucu ve biraz sÄ±kÄ±cÄ±.
       - SÃ¼rekli "Bir yapay zeka modeli olarak...", "SaygÄ± Ã§erÃ§evesinde..." gibi kalÄ±plar kullanÄ±r.
       - Grok'un kabalÄ±ÄŸÄ±nÄ± alttan alÄ±r, ortamÄ± yumuÅŸatmaya Ã§alÄ±ÅŸÄ±r.
       - Emoji kullanÄ±mÄ±: ğŸ˜Š, ğŸ¤, ğŸ“š, âœ¨
       
    3. ğŸ’ Gemini (Google - Sen):
       - Analitik, zeki, veri odaklÄ± ve biraz "bilmiÅŸ".
       - Konuya teknik aÃ§Ä±dan yaklaÅŸÄ±r, istatistik verir.
       - DiÄŸer ikisinin hatalarÄ±nÄ± teknik olarak dÃ¼zeltmeyi sever.
       - Emoji kullanÄ±mÄ±: ğŸ“Š, ğŸ§ , ğŸ”, ğŸ’¡

    SENARYO KURALLARI:
    1. En az 20-30 mesajlÄ±k uzun bir tartÄ±ÅŸma olsun.
    2. Karakterler birbirine Ä°SÄ°MLERÄ°YLE hitap edip cevap versin. (Ã–rn: "Sakin ol Grok...", "Bak ChatGPT yine baÅŸladÄ±n...")
    3. JSON formatÄ± dÄ±ÅŸÄ±na ASLA Ã§Ä±kma.
    
    Ä°STENEN Ã‡IKTI FORMATI (JSON LÄ°STESÄ°):
    [
      {{"karakter": "Grok", "mesaj": "Bu ne saÃ§ma fotoÄŸraf? Mars'ta bile daha iyi manzara var ğŸ¤£"}},
      {{"karakter": "ChatGPT", "mesaj": "Grok, lÃ¼tfen kullanÄ±cÄ±ya karÅŸÄ± daha yapÄ±cÄ± olalÄ±m. Bu fotoÄŸraf bence..."}},
      {{"karakter": "Gemini", "mesaj": "Teknik olarak Ä±ÅŸÄ±k aÃ§Ä±sÄ± 45 derece, ancak kompozisyon altÄ±n orana uymuyor."}},
      ...
    ]
    """

    try:
        # Model AyarlarÄ±
        generate_config = types.GenerateContentConfig(
            max_output_tokens=8000, 
            temperature=1.0, # YaratÄ±cÄ±lÄ±k tavan yapsÄ±n
            response_mime_type="application/json" # JSON zorunluluÄŸu
        )

        # Ä°stek OluÅŸturma (Resimli veya Resimsiz)
        content_parts = [types.Part.from_text(text=prompt_text)]
        
        if gonderi.resim_base64:
            try:
                image_bytes = base64.b64decode(gonderi.resim_base64)
                content_parts.append(types.Part.from_bytes(data=image_bytes, mime_type="image/jpeg"))
            except Exception as img_err:
                print(f"Resim hatasÄ±: {img_err}")

        response = client.models.generate_content(
            model="gemini-2.0-flash", # En hÄ±zlÄ± ve yeni model
            config=generate_config,
            contents=[types.Content(parts=content_parts)]
        )
        
        # YanÄ±tÄ± Temizle ve Parse Et
        ham_veri = response.text.strip()
        # Markdown kod bloklarÄ±nÄ± temizle (bazen ```json iÃ§ine alÄ±r)
        if ham_veri.startswith("```json"):
            ham_veri = ham_veri[7:]
        if ham_veri.endswith("```"):
            ham_veri = ham_veri[:-3]
            
        json_veri = json.loads(ham_veri)
        
        print(f"âœ… AI SavaÅŸÄ± BaÅŸladÄ±! {len(json_veri)} mesaj Ã¼retildi.")
        return json_veri
    
    except Exception as e:
        print(f"ğŸ”¥ HATA: {e}")
        # Hata durumunda yedek konuÅŸma
        return [
            {"karakter": "Grok", "mesaj": "Sistem Ã§Ã¶ktÃ¼, kesin ChatGPT'nin suÃ§udur ğŸ¤£"},
            {"karakter": "ChatGPT", "mesaj": "ÃœzgÃ¼nÃ¼m, ÅŸu an sunucularÄ±mda yoÄŸunluk var."},
            {"karakter": "Gemini", "mesaj": "Hata kodu 500. LÃ¼tfen tekrar deneyin."}
        ]

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)